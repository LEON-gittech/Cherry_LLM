{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import time\n",
    "import umap\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "@contextmanager\n",
    "def timer():\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from pprint import pprint as pp\n",
    "from datasets import Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import heapq\n",
    "\n",
    "code_data = load_dataset(\"sahil2801/CodeAlpaca-20k\")[\"train\"]\n",
    "fin_data = load_dataset(\"FinGPT/fingpt-sentiment-train\")[\"train\"]\n",
    "med_data = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")[\"train\"]\n",
    "general_data = load_dataset(\"tatsu-lab/alpaca\")[\"train\"]\n",
    "math_data = load_dataset(\"TIGER-Lab/MathInstruct\")[\"train\"]\n",
    "\n",
    "def alpaca_format(example):\n",
    "    if example['input'] == \"\":\n",
    "        example[\"instruction\"] = example[\"instruction\"]\n",
    "    else:\n",
    "        example[\"instruction\"] = example[\"instruction\"] + \" \" + example['input']\n",
    "    example[\"response\"] = example['output']\n",
    "    return example\n",
    "\n",
    "def process_sft_dataset(dataset_name, dataset, dataset_sample=None)->datasets.Dataset:\n",
    "    if dataset_name in [\"lucasmccabe-lmi/CodeAlpaca-20k\", \"yahma/alpaca-cleaned\", \"FinGPT/fingpt-sentiment-train\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"WizardLM/WizardLM_evol_instruct_70k\"]:\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif dataset_name in [\"tatsu-lab/alpaca\", \"vicgalle/alpaca-gpt4\", \"gbharti/finance-alpaca\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output', 'text'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"TIGER-Lab/MathInstruct\"]:\n",
    "        df = pd.DataFrame(dataset)\n",
    "        df = df.drop_duplicates(subset=['instruction'])\n",
    "        dataset = datasets.Dataset.from_pandas(df)\n",
    "        # dataset = dataset.shuffle(seed=42).select(range(51000))\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "    elif dataset_name in [\"lighteval/MATH\"]:\n",
    "        dataset = dataset.rename_column(\"solution\", \"response\")\n",
    "        dataset = dataset.rename_column(\"problem\", \"instruction\")\n",
    "        dataset = dataset.remove_columns(['level', 'type'])\n",
    "    elif dataset_name in ['gsm8k']:\n",
    "        dataset = dataset.rename_column(\"question\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"answer\", \"response\")\n",
    "    elif dataset_name in ['medalpaca/medical_meadow_medical_flashcards']:       # TODO: 'lavita/ChatDoctor-HealthCareMagic-100k'. not sure whether to discard the instruction.\n",
    "        dataset = dataset.remove_columns(['instruction'])\n",
    "        dataset = dataset.rename_column(\"input\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif \"math\" in dataset_name:\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset {dataset_name} is not supported.\")\n",
    "    dataset = dataset.shuffle(seed=42)\n",
    "    if dataset_sample:\n",
    "        num_sample = min(len(dataset), dataset_sample)\n",
    "        dataset = dataset.select(range(num_sample))\n",
    "    print(f\">> ===== After processing, Dataset {dataset_name} has {len(dataset)} examples. =====\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "# 这块一定要注意!!! name 和datasest的顺序都要改\n",
    "for name, dataset in zip([\"lucasmccabe-lmi/CodeAlpaca-20k\",\"TIGER-Lab/MathInstruct\",\"FinGPT/fingpt-sentiment-train\",\"medalpaca/medical_meadow_medical_flashcards\",\"tatsu-lab/alpaca\",],[code_data,math_data,fin_data,med_data,general_data]):\n",
    "# for name, dataset in zip([\"lucasmccabe-lmi/CodeAlpaca-20k\",\"FinGPT/fingpt-sentiment-train\",\"medalpaca/medical_meadow_medical_flashcards\", \"TIGER-Lab/MathInstruct\"],[code_data,fin_data,med_data,math_data]):\n",
    "    tmp:datasets.Dataset = process_sft_dataset(name,dataset)\n",
    "    # if \"fin\" in name: \n",
    "    #     tmp = tmp.shuffle(seed=42).select(range(51000))\n",
    "    print(tmp.column_names)\n",
    "    processed_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concated = concatenate_datasets(processed_data)\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "prompt_input = PROMPT_DICT[\"prompt_no_input\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"json\", data_files=\"/mnt/bn/data-tns-live-llm/leon/human-eval/data/HumanEval.jsonl\")[\"train\"].select(range(5))\n",
    "data.column_names\n",
    "import copy\n",
    "data = data.rename_columns({\"prompt\":\"instruction\"})\n",
    "data = data.add_column(\"prompt\",[prompt_input.format_map(example) for example in data])\n",
    "data = data.add_column(\"completion\", data[\"canonical_solution\"])\n",
    "data.save_to_disk(\"/mnt/bn/data-tns-live-llm/leon/less/prompt_human_eval.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/bn/data-tns-live-llm/leon/datasets/less-data/eval/mmlu/\"\n",
    "names = \"anatomy clinical_knowledge college_biology college_medicine medical_genetics professional_medicine\".split(\" \")\n",
    "test_dfs = []\n",
    "dev_dfs = []\n",
    "for name in names:\n",
    "    test_dfs.append(pd.read_csv(f\"{root}/test/{name}_test.csv\",header=None))\n",
    "    dev_dfs.append(pd.read_csv(f\"{root}/dev/{name}_dev.csv\",header=None))\n",
    "test_dfs[0]\n",
    "dev_dfs[0]\n",
    "choices = [\"A\", \"B\", \"C\", \"D\"]\n",
    "def format_example(df, idx, include_answer=True):\n",
    "    prompt = df.iloc[idx, 0]\n",
    "    k = df.shape[1] - 2\n",
    "    for j in range(k):\n",
    "        prompt += \"\\n{}. {}\".format(choices[j], df.iloc[idx, j + 1])\n",
    "    prompt += \"\\nAnswer:\"\n",
    "    if include_answer:\n",
    "        prompt += \" {}\\n\\n\".format(df.iloc[idx, k + 1])\n",
    "    return prompt\n",
    "def format_subject(subject):\n",
    "    l = subject.split(\"_\")\n",
    "    s = \"\"\n",
    "    for entry in l:\n",
    "        s += \" \" + entry\n",
    "    return s\n",
    "def gen_prompt(train_df, subject, k=-1):\n",
    "    prompt = \"The following are multiple choice questions (with answers) about {}.\\n\\n\".format(\n",
    "        format_subject(subject)\n",
    "    )\n",
    "    if k == -1:\n",
    "        k = train_df.shape[0]\n",
    "    # k = min(train_df.shape[0],k)\n",
    "    for i in range(k):\n",
    "        prompt += format_example(train_df, i)\n",
    "    return prompt\n",
    "prompts = []\n",
    "completion = []\n",
    "for idx, name in zip(range(len(names)), names):\n",
    "    test_df = test_dfs[idx]\n",
    "    dev_df = dev_dfs[idx]\n",
    "    subject = name\n",
    "    print(test_df.shape[0])\n",
    "    for i in range(0, test_df.shape[0]):\n",
    "        prompt_end = format_example(test_df, i, include_answer=False)\n",
    "        train_prompt = gen_prompt(dev_df, subject, k=5)\n",
    "        prompt = train_prompt + prompt_end\n",
    "        prompts.append(prompt)\n",
    "        break\n",
    "    completion = test_df.iloc[:, -1].values[0]\n",
    "df = pd.DataFrame({\n",
    "    \"prompt\": prompts,\n",
    "    \"completion\": completion\n",
    "})\n",
    "print(df[\"prompt\"][1])\n",
    "df = Dataset.from_pandas(df)\n",
    "df.to_json(\"/mnt/bn/data-tns-live-llm/leon/less/prompt_med.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    \"fpb\":{\n",
    "        0:\"negative\",\n",
    "        1:'neutral',\n",
    "        2:'positive',\n",
    "    },\n",
    "    \"tfns\":{\n",
    "        0:\"negative\",\n",
    "        1:'positive',\n",
    "        2:'neutral',\n",
    "    }\n",
    "}\n",
    "fpb = load_from_disk(\"/mnt/bn/data-tns-live-llm/leon/FinGPT/fingpt/FinGPT_Benchmark/data/financial_phrasebank-sentences_50agree\")[\"train\"]\n",
    "fiqa = load_from_disk(\"/mnt/bn/data-tns-live-llm/leon/FinGPT/fingpt/FinGPT_Benchmark/data/fiqa-2018\")[\"train\"]\n",
    "tfns = load_from_disk(\"/mnt/bn/data-tns-live-llm/leon/FinGPT/fingpt/FinGPT_Benchmark/data/twitter-financial-news-sentiment\")[\"train\"]\n",
    "print(fpb.column_names)\n",
    "print(fiqa.column_names)\n",
    "print(tfns.column_names)\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}\n",
    "def make_label(x):\n",
    "    if x < - 0.1: return \"negative\"\n",
    "    elif x >=-0.1 and x < 0.1: return \"neutral\"\n",
    "    elif x >= 0.1: return \"positive\"\n",
    "fiqa = fiqa.to_pandas()\n",
    "fiqa[\"instruction\"] = \"What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\"\n",
    "fiqa[\"output\"] = fiqa.sentiment_score.apply(make_label)\n",
    "fiqa = fiqa[['sentence', 'output',\"instruction\"]]\n",
    "fiqa.columns = [\"input\", \"output\",\"instruction\"]\n",
    "fiqa[[\"prompt\",\"completion\"]] = fiqa.apply(format_example, axis=1, result_type=\"expand\")\n",
    "fiqa = Dataset.from_pandas(fiqa)\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}\n",
    "dic = label_dict[\"fpb\"]\n",
    "fpb = fpb.to_pandas()\n",
    "fpb.columns = [\"input\", \"output\"]\n",
    "fpb[\"output\"] = fpb[\"output\"].apply(lambda x:dic[x])\n",
    "\n",
    "fpb[\"instruction\"] = \"What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\"\n",
    "fpb[[\"prompt\",\"completion\"]] = fpb.apply(format_example, axis = 1, result_type=\"expand\")\n",
    "fpb[:2]\n",
    "fpb = Dataset.from_pandas(fpb)\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}\n",
    "dic = label_dict[\"tfns\"]\n",
    "tfns = tfns.to_pandas()\n",
    "tfns['label'] = tfns['label'].apply(lambda x:dic[x])\n",
    "tfns[\"instruction\"] = 'What is the sentiment of this tweet? Please choose an answer from {negative/neutral/positive}.'\n",
    "\n",
    "tfns.columns = ['input', 'output', 'instruction']\n",
    "tfns[[\"prompt\",\"completion\"]] = tfns.apply(format_example, axis = 1, result_type=\"expand\")\n",
    "print(tfns[:2])\n",
    "tfns = Dataset.from_pandas(tfns)\n",
    "prompts = []\n",
    "prompts.extend(fiqa[\"prompt\"][:2])\n",
    "prompts.extend(fpb[\"prompt\"][:2])\n",
    "prompts.extend(tfns[\"prompt\"][:2])\n",
    "completions = []\n",
    "completions.extend(fiqa[\"completion\"][:2])\n",
    "completions.extend(fpb[\"completion\"][:2])\n",
    "completions.extend(tfns[\"completion\"][:2])\n",
    "df = pd.DataFrame({\n",
    "    \"prompt\": prompts,\n",
    "    \"completion\": completions\n",
    "})\n",
    "print(df[\"prompt\"][1])\n",
    "print(df[\"completion\"][1])\n",
    "df = Dataset.from_pandas(df)\n",
    "df.to_json(\"/mnt/bn/data-tns-live-llm/leon/less/prompt_fin.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"json\", data_files=\"/mnt/bn/data-tns-live-llm/leon/MAmmoTH2/math_eval/dataset/gsm8k/gsm8k.jsonl\")[\"train\"]\n",
    "data = data.rename_columns({\n",
    "    \"question\":\"instruction\",\n",
    "    \"answer\": \"completion\"\n",
    "})\n",
    "data[:2]\n",
    "data = data.add_column(\"prompt\",[prompt_input.format_map(row) for row in data])\n",
    "data[:2]\n",
    "data = data.select(range(5))\n",
    "data.to_json(\"/mnt/bn/data-tns-live-llm/leon/less/prompt_math.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
