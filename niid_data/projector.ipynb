{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "import time\n",
    "import umap\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "@contextmanager\n",
    "def timer():\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 8*GPUs----------\n"
     ]
    }
   ],
   "source": [
    "model_s = FlagModel('BAAI/bge-large-en-v1.5', \n",
    "                  query_instruction_for_retrieval=\"\",\n",
    "                  use_fp16=True,\n",
    "                )\n",
    "model_c = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', model_kwargs={\"torch_dtype\":torch.float16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> ===== After processing, Dataset TIGER-Lab/MathInstruct has 224567 examples. =====\n",
      "['response', 'instruction', '__index_level_0__']\n",
      ">> ===== After processing, Dataset FinGPT/fingpt-sentiment-train has 76772 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset medalpaca/medical_meadow_medical_flashcards has 33955 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset lucasmccabe-lmi/CodeAlpaca-20k has 20022 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset tatsu-lab/alpaca has 52002 examples. =====\n",
      "['instruction', 'response']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from pprint import pprint as pp\n",
    "from datasets import Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import heapq\n",
    "code_data = load_dataset(\"sahil2801/CodeAlpaca-20k\")[\"train\"]\n",
    "fin_data = load_dataset(\"FinGPT/fingpt-sentiment-train\")[\"train\"]\n",
    "med_data = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")[\"train\"]\n",
    "general_data = load_dataset(\"tatsu-lab/alpaca\")[\"train\"]\n",
    "math_data = load_dataset(\"TIGER-Lab/MathInstruct\")[\"train\"]\n",
    "\n",
    "def alpaca_format(example):\n",
    "    if example['input'] == \"\":\n",
    "        example[\"instruction\"] = example[\"instruction\"]\n",
    "    else:\n",
    "        example[\"instruction\"] = example[\"instruction\"] + \" \" + example['input']\n",
    "    example[\"response\"] = example['output']\n",
    "    return example\n",
    "\n",
    "def process_sft_dataset(dataset_name, dataset, dataset_sample=None)->datasets.Dataset:\n",
    "    if dataset_name in [\"lucasmccabe-lmi/CodeAlpaca-20k\", \"yahma/alpaca-cleaned\", \"FinGPT/fingpt-sentiment-train\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"WizardLM/WizardLM_evol_instruct_70k\"]:\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif dataset_name in [\"tatsu-lab/alpaca\", \"vicgalle/alpaca-gpt4\", \"gbharti/finance-alpaca\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output', 'text'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"TIGER-Lab/MathInstruct\"]:\n",
    "        df = pd.DataFrame(dataset)\n",
    "        df = df.drop_duplicates(subset=['instruction'])\n",
    "        dataset = datasets.Dataset.from_pandas(df)\n",
    "        # dataset = dataset.shuffle(seed=42).select(range(51000))\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "    elif dataset_name in [\"lighteval/MATH\"]:\n",
    "        dataset = dataset.rename_column(\"solution\", \"response\")\n",
    "        dataset = dataset.rename_column(\"problem\", \"instruction\")\n",
    "        dataset = dataset.remove_columns(['level', 'type'])\n",
    "    elif dataset_name in ['gsm8k']:\n",
    "        dataset = dataset.rename_column(\"question\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"answer\", \"response\")\n",
    "    elif dataset_name in ['medalpaca/medical_meadow_medical_flashcards']:       # TODO: 'lavita/ChatDoctor-HealthCareMagic-100k'. not sure whether to discard the instruction.\n",
    "        dataset = dataset.remove_columns(['instruction'])\n",
    "        dataset = dataset.rename_column(\"input\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif \"math\" in dataset_name:\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset {dataset_name} is not supported.\")\n",
    "    dataset = dataset.shuffle(seed=42)\n",
    "    if dataset_sample:\n",
    "        num_sample = min(len(dataset), dataset_sample)\n",
    "        dataset = dataset.select(range(num_sample))\n",
    "    print(f\">> ===== After processing, Dataset {dataset_name} has {len(dataset)} examples. =====\")\n",
    "    return dataset\n",
    "\n",
    "processed_data = []\n",
    "# 这块一定要注意!!! name 和datasest的顺序都要改\n",
    "for name, dataset in zip([\"TIGER-Lab/MathInstruct\",\"FinGPT/fingpt-sentiment-train\",\"medalpaca/medical_meadow_medical_flashcards\",\"lucasmccabe-lmi/CodeAlpaca-20k\",\"tatsu-lab/alpaca\",],[math_data,fin_data,med_data,code_data,general_data]):\n",
    "# for name, dataset in zip([\"lucasmccabe-lmi/CodeAlpaca-20k\",\"FinGPT/fingpt-sentiment-train\",\"medalpaca/medical_meadow_medical_flashcards\", \"TIGER-Lab/MathInstruct\"],[code_data,fin_data,med_data,math_data]):\n",
    "    tmp:datasets.Dataset = process_sft_dataset(name,dataset)\n",
    "    # if \"fin\" in name: \n",
    "    #     tmp = tmp.shuffle(seed=42).select(range(51000))\n",
    "    print(tmp.column_names)\n",
    "    processed_data.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concated = concatenate_datasets(processed_data)[\"instruction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 796/796 [11:08<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_s = model_s.encode(data_concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = model_c.start_multi_process_pool()\n",
    "embeddings_c = torch.tensor(model_c.encode_multi_process(data_concated,pool,precision='float32'))\n",
    "model_c.stop_multi_process_pool(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_c[0].shape)\n",
    "embeddings_s = torch.Tensor(embeddings_s)\n",
    "print(embeddings_s[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Projector, self).__init__()\n",
    "        self.fc1 = nn.Linear(384, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, anchor, positive, negatives) -> torch.Tensor:\n",
    "        anchor_pos_similarity = (anchor * positive).sum(dim=1) / self.temperature\n",
    "        anchor_neg_similarity = (anchor.unsqueeze(1) * negatives).sum(dim=2) / self.temperature\n",
    "\n",
    "        logits = torch.cat([anchor_pos_similarity.unsqueeze(1), anchor_neg_similarity], dim=1)\n",
    "        labels = torch.zeros(logits.size(0), dtype=torch.long, device=logits.device)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(logits, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, embeddings_c, embeddings_s):\n",
    "        \"\"\"\n",
    "        初始化数据集。\n",
    "        :param embeddings_c: 384维的embeddings。\n",
    "        :param embeddings_s: 1024维的embeddings，与embeddings_c一一对应。\n",
    "        \"\"\"\n",
    "        self.embeddings_c = embeddings_c\n",
    "        self.embeddings_s = embeddings_s\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中样本的数量。\n",
    "        \"\"\"\n",
    "        return len(self.embeddings_c)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        根据索引idx获取一个样本。\n",
    "        \"\"\"\n",
    "        # 获取对应的embeddings_c和embeddings_s\n",
    "        embeddings_c_sample = self.embeddings_c[idx]\n",
    "        embeddings_s_sample = self.embeddings_s[idx]\n",
    "\n",
    "        return embeddings_c_sample, embeddings_s_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集实例\n",
    "dataset = CustomDataset(embeddings_c, embeddings_s)\n",
    "# 创建DataLoader实例\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.0251: 100%|██████████| 12729/12729 [03:51<00:00, 54.96it/s]\n",
      "Batch loss: 0.0185: 100%|██████████| 12729/12729 [03:49<00:00, 55.56it/s]\n",
      "Batch loss: 0.0015: 100%|██████████| 12729/12729 [03:26<00:00, 61.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# 实例化投影器和损失函数\n",
    "projector = Projector().cuda()\n",
    "criterion = ContrastiveLoss(temperature=0.5)\n",
    "num_epochs = 3\n",
    "# 选择优化器\n",
    "optimizer = torch.optim.Adam(projector.parameters(), lr=1e-4)\n",
    "\n",
    "# 假设 dataloader 产生 (embeddings_c_batch, embeddings_s_batch) 形式的数据\n",
    "for epoch in range(num_epochs):\n",
    "    tqdm_dataloader = tqdm(enumerate(dataloader), desc=f'Epoch {epoch+1}/{num_epochs}', total=len(dataloader))\n",
    "    for batch_idx, (embeddings_c_batch, embeddings_s_batch) in tqdm_dataloader:\n",
    "        # 将 embeddings_c 投影到更高维度的空间\n",
    "        embeddings_c_batch, embeddings_s_batch = embeddings_c_batch.cuda(), embeddings_s_batch.cuda()\n",
    "        projected_c_batch = projector(embeddings_c_batch)\n",
    "        # 初始化总损失\n",
    "        total_loss = 0\n",
    "        # 计算每个样本的损失并累加\n",
    "        for i in range(len(embeddings_c_batch)):\n",
    "            # 取出第 i 个样本的正样本嵌入\n",
    "            positive = embeddings_s_batch[i]\n",
    "            # 取出第 i 个样本的负样本嵌入，这里我们取批次中除了自身之外的其他样本\n",
    "            negatives = torch.stack([embeddings_s_batch[j] for j in range(len(embeddings_c_batch)) if j != i])\n",
    "            # 计算损失\n",
    "            loss = criterion(projected_c_batch[i].unsqueeze(0), positive.unsqueeze(0), negatives)\n",
    "            # 累加损失\n",
    "            total_loss += loss\n",
    "        # 计算批次的平均损失\n",
    "        batch_loss = total_loss / len(embeddings_c_batch)\n",
    "        tqdm_dataloader.set_description(f'Batch loss: {batch_loss:.4f}')\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(projector.state_dict(), '/mnt/bn/data-tns-live-llm/leon/datasets/projector_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12619/84120828.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  projector.load_state_dict(torch.load('/mnt/bn/data-tns-live-llm/leon/datasets/projector_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projector = Projector().cuda()\n",
    "projector.load_state_dict(torch.load('/mnt/bn/data-tns-live-llm/leon/datasets/projector_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223567\n"
     ]
    }
   ],
   "source": [
    "data_concated: Dataset = processed_data[0]\n",
    "random.seed(42)\n",
    "iid_idxs = random.sample(range(len(data_concated)), 1000)\n",
    "base_data = data_concated.select(iid_idxs)\n",
    "clients_data = []\n",
    "for i in range(10):\n",
    "    clients_data.append(base_data.shard(10,i))\n",
    "\n",
    "data_concated = data_concated.select(list(set(range(len(data_concated)))-set(iid_idxs)))\n",
    "print(len(data_concated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "base_0_embeddings = model_c.encode(clients_data[0][\"instruction\"])\n",
    "# 假设 embeddings 是你的嵌入数据\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(base_0_embeddings)\n",
    "labels = kmeans.labels_\n",
    "# 计算每个簇的样本数量\n",
    "counts = np.bincount(labels)\n",
    "# 找到最大的簇的标签\n",
    "largest_cluster_label = np.argmax(counts)\n",
    "# 从 cluster_centers_ 中获取最大的簇的中心\n",
    "cluster_center_0:np.array = kmeans.cluster_centers_[largest_cluster_label]\n",
    "print(cluster_center_0.shape)\n",
    "client_clusters = cluster_center_0.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10-1):\n",
    "    i=i+1\n",
    "    base_i_embeddings = model_c.encode(clients_data[i][\"instruction\"])\n",
    "    # 假设 embeddings 是你的嵌入数据\n",
    "    kmeans = KMeans(n_clusters=10, random_state=0).fit(base_i_embeddings)\n",
    "    labels = kmeans.labels_\n",
    "    similarity_scores = np.sum(kmeans.cluster_centers_ @ client_clusters.T, axis=-1)\n",
    "    print(similarity_scores.shape)\n",
    "    selected_idxs = np.argsort(similarity_scores)[i:]      \n",
    "    # 计算每个簇的样本数量\n",
    "    counts = np.bincount(labels)\n",
    "    # 找到最大的簇的标签\n",
    "    largest_cluster_labels = np.argsort(-counts) #降序\n",
    "    largest_cluster_label = -1\n",
    "    for j in largest_cluster_labels:\n",
    "        if j in selected_idxs:\n",
    "            largest_cluster_label = j\n",
    "    # 从 cluster_centers_ 中获取最大的簇的中心\n",
    "    largest_cluster_center = kmeans.cluster_centers_[largest_cluster_label]\n",
    "    client_clusters = np.concatenate([client_clusters,largest_cluster_center.reshape((1,-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings:   0%|          | 0/199 [00:00<?, ?it/s]/home/tiger/.local/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "Inference Embeddings: 100%|██████████| 199/199 [06:40<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "data_concated: Dataset = concatenate_datasets(processed_data)\n",
    "data_concated = data_concated.select(list(set(range(len(data_concated)))-set(iid_idxs)))\n",
    "print(len(data_concated))\n",
    "concated_embeddings = model_s.encode(data_concated[\"instruction\"])\n",
    "concated_embeddings = torch.tensor(concated_embeddings, dtype=torch.float32)\n",
    "client_clusters = torch.tensor(client_clusters, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12619/3190044094.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  client_clusters = torch.tensor(client_clusters, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_clusters = projector(client_clusters.cuda())\n",
    "client_clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d17fefd59eb4affb88ef8c4e593516f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e7426e8e52469a86cd377dff32b7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dfd6ab870044a6bf5005e5d5a263e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0b29522a62488a8d6ff6d579020167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2669946bb9e340ffbe4f7fb3af567d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e43bf0c9e9f4357be4bd1d03ad4d4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c13ec8a77437fa80a563211d7f7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a8e61848ba4d6088f8e1fb87dc3b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/626 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c54eea179f487abe952083a0c4714e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c53e8f8bf9547679adb1bb866322a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "retrival_nums = [5000]\n",
    "domain = \"math\"\n",
    "for retrival_num in retrival_nums:\n",
    "    client_pos_datasets = []\n",
    "    for i, sampled_data in enumerate(clients_data):\n",
    "        print(i)\n",
    "        similarity_scores = torch.matmul(client_clusters[i,:].cuda(), (concated_embeddings.T).cuda()).cpu()\n",
    "        # filter\n",
    "        filtered_scores = [(score.item(), idx) for idx, score in enumerate(similarity_scores) if score < 0.7]\n",
    "        top_idxs = heapq.nlargest(retrival_num, range(len(filtered_scores)-1), key=lambda x:filtered_scores[x])\n",
    "        # no filter\n",
    "        # top_idxs = heapq.nlargest(5000, range(len(similarity_scores)-1), key=lambda x: similarity_scores[x])\n",
    "        pos_datasets: Dataset = []\n",
    "        pos_datasets = data_concated.select(top_idxs)\n",
    "        pos_datasets = concatenate_datasets([pos_datasets, sampled_data])\n",
    "        pos_datasets = pos_datasets.shuffle(seed=42)\n",
    "        client_pos_datasets.append(pos_datasets)\n",
    "        \n",
    "    for i, pos_data in enumerate(client_pos_datasets):\n",
    "        pos_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/iid2niid_{domain}_{retrival_num}_projector_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
