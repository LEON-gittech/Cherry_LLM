{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptsource.templates import DatasetTemplates, TemplateCollection\n",
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_collection = TemplateCollection()\n",
    "collection_templates = template_collection.datasets_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = list(template_collection.datasets_templates.keys())\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(template_collection.datasets_templates[\"ai2_arc\",'ARC-Easy'].templates[\"033498ca-3d9a-47e3-b631-d881ab53b5ad\"].jinja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'24e44a81-a18a-42dd-a71c-5b31b2d2cb39': <promptsource.templates.Template object at 0x7fc3275d61f0>, '8fdc1056-1029-41a1-9c67-354fc2b8ceaf': <promptsource.templates.Template object at 0x7fc3275d61c0>, '918267e0-af68-4117-892d-2dbe66a58ce9': <promptsource.templates.Template object at 0x7fc3275d6e50>, '9345df33-4f23-4944-a33c-eef94e626862': <promptsource.templates.Template object at 0x7fc3275da190>, '98534347-fff7-4c39-a795-4e69a44791f7': <promptsource.templates.Template object at 0x7fc3275da1c0>, 'b401b0ee-6ffe-4a91-8e15-77ee073cd858': <promptsource.templates.Template object at 0x7fc3275da1f0>, 'cb355f33-7e8c-4455-a72b-48d315bd4f60': <promptsource.templates.Template object at 0x7fc3275da130>}\n"
     ]
    }
   ],
   "source": [
    "ag_news_prompts = DatasetTemplates('ag_news')\n",
    "print(ag_news_prompts.templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What label best describes this news article?\n",
      "{{text}} ||| \n",
      "{{answer_choices[label] }}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "tmp = ag_news_prompts.templates\n",
    "print(tmp['24e44a81-a18a-42dd-a71c-5b31b2d2cb39'].jinja)\n",
    "print(type(tmp['24e44a81-a18a-42dd-a71c-5b31b2d2cb39'].jinja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['24e44a81-a18a-42dd-a71c-5b31b2d2cb39', '8fdc1056-1029-41a1-9c67-354fc2b8ceaf', '918267e0-af68-4117-892d-2dbe66a58ce9', '9345df33-4f23-4944-a33c-eef94e626862', '98534347-fff7-4c39-a795-4e69a44791f7', 'b401b0ee-6ffe-4a91-8e15-77ee073cd858', 'cb355f33-7e8c-4455-a72b-48d315bd4f60'])\n",
      "{'answer_choices': 'World politics ||| Sports ||| Business ||| Science and technology', 'id': '24e44a81-a18a-42dd-a71c-5b31b2d2cb39', 'jinja': 'What label best describes this news article?\\n{{text}} ||| \\n{{answer_choices[label] }}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da160>, 'name': 'classify_question_first', 'reference': ''}\n",
      "{'answer_choices': 'World politics ||| Sports ||| Business ||| Science and technology', 'id': '8fdc1056-1029-41a1-9c67-354fc2b8ceaf', 'jinja': 'Is this a piece of news regarding {{\"world politics, sports, business, or science and technology\"}}?\\n{{text}} \\n||| \\n{{answer_choices[label] }}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da0a0>, 'name': 'classify_with_choices_question_first', 'reference': ''}\n",
      "{'answer_choices': 'Politician ||| Athlete ||| Business executive ||| Scientist', 'id': '918267e0-af68-4117-892d-2dbe66a58ce9', 'jinja': 'Would you recommend the following article to a {{\"politician\"}}, an {{\"athlete\"}}, a {{\"business executive\"}}, or a {{\"scientist\"}}?\\n\\n{{ text }}\\n|||\\n{{answer_choices[label]}}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da0d0>, 'name': 'recommend', 'reference': ''}\n",
      "{'answer_choices': 'World News ||| Sports ||| Business ||| Science and Technology', 'id': '9345df33-4f23-4944-a33c-eef94e626862', 'jinja': '{{text}} \\n\\nWhich of the following sections of a newspaper would this article likely appear in? {{\"World News\"}}, {{\"Sports\"}}, {{\"Business\"}}, or {{\"Science and Technology\"}}? ||| \\n{{answer_choices[label] }}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da220>, 'name': 'which_section_choices', 'reference': ''}\n",
      "{'answer_choices': 'World News ||| Sports ||| Business ||| Science and Technology', 'id': '98534347-fff7-4c39-a795-4e69a44791f7', 'jinja': '{{text}} \\n\\nWhich section of a newspaper would this article likely appear in? ||| \\n{{answer_choices[label] }}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da250>, 'name': 'which_section', 'reference': ''}\n",
      "{'answer_choices': 'World politics ||| Sports ||| Business ||| Science and technology', 'id': 'b401b0ee-6ffe-4a91-8e15-77ee073cd858', 'jinja': '{{text}} \\nIs this a piece of news regarding {{\"world politics, sports, business, or science and technology\"}}? ||| \\n{{answer_choices[label] }}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da040>, 'name': 'classify_with_choices', 'reference': ''}\n",
      "{'answer_choices': 'World politics ||| Sports ||| Business ||| Science and technology', 'id': 'cb355f33-7e8c-4455-a72b-48d315bd4f60', 'jinja': '{{text}} \\nWhat label best describes this news article? ||| \\n{{answer_choices[label] }}', 'metadata': <promptsource.templates.Template.Metadata object at 0x7fc3275da280>, 'name': 'classify', 'reference': ''}\n"
     ]
    }
   ],
   "source": [
    "print(tmp.keys())\n",
    "for k in list(tmp.keys()):\n",
    "    print(tmp[k].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ag_news\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What label best describes this news article?\\n'\n",
      "  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market.',\n",
      "  'Business'],\n",
      " ['Is this a piece of news regarding world politics, sports, business, or '\n",
      "  'science and technology?\\n'\n",
      "  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market.',\n",
      "  'Business'],\n",
      " ['Would you recommend the following article to a politician, an athlete, a '\n",
      "  'business executive, or a scientist?\\n'\n",
      "  '\\n'\n",
      "  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market.',\n",
      "  'Business executive'],\n",
      " ['Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market. \\n'\n",
      "  '\\n'\n",
      "  'Which of the following sections of a newspaper would this article likely '\n",
      "  'appear in? World News, Sports, Business, or Science and Technology?',\n",
      "  'Business'],\n",
      " ['Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market. \\n'\n",
      "  '\\n'\n",
      "  'Which section of a newspaper would this article likely appear in?',\n",
      "  'Business'],\n",
      " ['Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market. \\n'\n",
      "  'Is this a piece of news regarding world politics, sports, business, or '\n",
      "  'science and technology?',\n",
      "  'Business'],\n",
      " ['Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private '\n",
      "  'investment firm Carlyle Group,\\\\which has a reputation for making '\n",
      "  'well-timed and occasionally\\\\controversial plays in the defense industry, '\n",
      "  'has quietly placed\\\\its bets on another part of the market. \\n'\n",
      "  'What label best describes this news article?',\n",
      "  'Business']]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "instructions = []\n",
    "for k in list(tmp.keys()):\n",
    "    instructions.append(tmp[k].apply(example))\n",
    "pp(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What label best describes this news article?\\nCarlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', 'Business']\n"
     ]
    }
   ],
   "source": [
    "print((instructions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造 instructions 字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonsenseqa,dream,quail,quartz,social_iqa,wiqa,cosmos,qasc,quarel,sciq,wiki_hop,arc,openbookqa,multirc,piqa,race,hellaswag,boolq,adversarial_qa,quoref,duorc,ropes,squad_v2,record,hotpot_qa,wiki_qa,trivia_qa,web_questions,common_gen,wiki_bio,amazon,app_reviews,imdb,rotten_tomatoes,yelp,cnn_daily_mail,gigaword,multinews,samsum,xsum,ag_news,dbpedia,trec,mrpc,paws,qqp,anli,cb,rte,wsc,winogrande,wic,copa,hellaswag,story_cloze\n"
     ]
    }
   ],
   "source": [
    "task_dataset_list = \"\"\"CommonsenseQA\n",
    "DREAM\n",
    "QUAIL\n",
    "QuaRTz\n",
    "Social IQA\n",
    "WiQA\n",
    "Cosmos\n",
    "QASC\n",
    "Quarel\n",
    "SciQ\n",
    "Wiki Hop\n",
    "ARC\n",
    "OpenBookQA\n",
    "MultiRC\n",
    "PIQA\n",
    "RACE\n",
    "HellaSwag\n",
    "BoolQ\n",
    "Adversarial QA\n",
    "Quoref\n",
    "DuoRC\n",
    "ROPES\n",
    "SQuAD v2\n",
    "ReCoRD\n",
    "Hotpot QA\n",
    "Wiki QA\n",
    "Trivia QA\n",
    "Web Questions\n",
    "Common Gen\n",
    "Wiki Bio\n",
    "Amazon\n",
    "App Reviews\n",
    "IMDB\n",
    "Rotten Tomatoes\n",
    "Yelp\n",
    "CNN Daily Mail\n",
    "Gigaword\n",
    "MultiNews\n",
    "SamSum\n",
    "XSum\n",
    "AG News\n",
    "DBPedia\n",
    "TREC\n",
    "MRPC\n",
    "PAWS\n",
    "QQP\n",
    "ANLI\n",
    "CB\n",
    "RTE\n",
    "WSC\n",
    "Winogrande\n",
    "WiC\n",
    "COPA\n",
    "HellaSwag\n",
    "Story Cloze\"\"\".replace(\"\\n\",\",\").replace(\" \",\"_\").lower()\n",
    "print(task_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('neural_code_search', 'evaluation_dataset'), ('narrativeqa', None), ('winograd_wsc', 'wsc285'), ('winograd_wsc', 'wsc273'), ('paws', 'labeled_final'), ('paws', 'labeled_swap'), ('paws', 'unlabeled_final'), ('trivia_qa', 'unfiltered'), ('craffel/openai_lambada', None), ('math_dataset', 'algebra__linear_1d_composed'), ('math_dataset', 'algebra__linear_1d'), ('math_dataset', 'algebra__linear_2d_composed'), ('math_dataset', 'algebra__linear_2d'), ('biosses', None), ('mc_taco', None), ('cos_e', 'v1.11'), ('cos_e', 'v1.0'), ('scan', 'addprim_jump'), ('scan', 'template_right'), ('scan', 'template_around_right'), ('scan', 'filler_num3'), ('scan', 'length'), ('scan', 'filler_num0'), ('scan', 'template_jump_around_right'), ('scan', 'filler_num2'), ('scan', 'addprim_turn_left'), ('scan', 'filler_num1'), ('scan', 'simple'), ('scan', 'template_opposite_right'), ('rotten_tomatoes', None), ('ai2_arc', 'ARC-Challenge'), ('ai2_arc', 'ARC-Easy'), ('multi_nli', None), ('squad_v2', None), ('common_gen', None), ('swag', 'regular'), ('conv_ai_2', None), ('wiki_qa', None), ('fever', 'v1.0'), ('fever', 'v2.0'), ('sst', 'default'), ('jfleg', None), ('ecthr_cases', 'alleged-violation-prediction'), ('great_code', None), ('qasc', None), ('acronym_identification', None), ('freebase_qa', None), ('circa', None), ('ambig_qa', 'light'), ('riddle_sense', None), ('sick', None), ('hotpot_qa', 'fullwiki'), ('hotpot_qa', 'distractor'), ('sem_eval_2010_task_8', None), ('squad_adversarial', 'AddSent'), ('mdd', 'task3_qarecs'), ('mdd', 'task1_qa'), ('mdd', 'task2_recs'), ('social_i_qa', None), ('xquad', 'xquad.en'), ('yahoo_answers_qa', None), ('hyperpartisan_news_detection', 'byarticle'), ('hyperpartisan_news_detection', 'bypublisher'), ('wino_bias', 'type1_anti'), ('wino_bias', 'type2_pro'), ('wino_bias', 'type2_anti'), ('wino_bias', 'type1_pro'), ('craigslist_bargains', None), ('yahoo_answers_topics', None), ('openbookqa', 'additional'), ('openbookqa', 'main'), ('wiki_bio', None), ('codah', 'codah'), ('codah', 'fold_2'), ('codah', 'fold_3'), ('codah', 'fold_4'), ('codah', 'fold_1'), ('codah', 'fold_0'), ('samsum', None), ('liar', None), ('hlgd', None), ('generated_reviews_enth', None), ('climate_fever', None), ('stsb_multi_mt', 'en'), ('quartz', None), ('sem_eval_2014_task_1', None), ('squadshifts', 'new_wiki'), ('squadshifts', 'amazon'), ('squadshifts', 'nyt'), ('sciq', None), ('kelm', None), ('esnli', None), ('wiki_split', None), ('bing_coronavirus_query_set', None), ('tydiqa', 'secondary_task'), ('tydiqa', 'primary_task'), ('code_x_glue_tc_text_to_code', None), ('financial_phrasebank', 'sentences_allagree'), ('nlu_evaluation_data', None), ('cnn_dailymail', '3.0.0'), ('docred', None), ('piqa', None), ('crows_pairs', None), ('tmu_gfm_dataset', None), ('emotion', None), ('adversarial_qa', 'droberta'), ('adversarial_qa', 'adversarialQA'), ('adversarial_qa', 'dbert'), ('adversarial_qa', 'dbidaf'), ('quoref', None), ('mwsc', None), ('meta_woz', 'dialogues'), ('asnq', None), ('nq_open', None), ('xquad_r', 'en'), ('blended_skill_talk', None), ('species_800', None), ('winogrande', 'winogrande_l'), ('winogrande', 'winogrande_s'), ('winogrande', 'winogrande_debiased'), ('winogrande', 'winogrande_xl'), ('winogrande', 'winogrande_m'), ('winogrande', 'winogrande_xs'), ('medical_questions_pairs', None), ('cosmos_qa', None), ('hate_speech18', None), ('numer_sense', None), ('scicite', None), ('mocha', None), ('imdb', None), ('super_glue', 'wic'), ('super_glue', 'wsc.fixed'), ('super_glue', 'rte'), ('super_glue', 'axb'), ('super_glue', 'boolq'), ('super_glue', 'multirc'), ('super_glue', 'record'), ('super_glue', 'copa'), ('super_glue', 'cb'), ('super_glue', 'axg'), ('yelp_polarity', None), ('story_cloze', '2016'), ('scitldr', 'Abstract'), ('hellaswag', None), ('math_qa', None), ('wiki_hop', 'original'), ('wiki_hop', 'masked'), ('sent_comp', None), ('discovery', 'discovery'), ('snli', None), ('google_wellformed_query', None), ('commonsense_qa', None), ('aqua_rat', 'raw'), ('jigsaw_unintended_bias', None), ('quail', None), ('scientific_papers', 'pubmed'), ('scientific_papers', 'arxiv'), ('paws-x', 'en'), ('scitail', 'snli_format'), ('scitail', 'tsv_format'), ('yelp_review_full', None), ('turk', None), ('drop', None), ('enriched_web_nlg', 'en'), ('Zaid/coqa_expanded', None), ('Zaid/quac_expanded', None), ('qed', None), ('conv_ai', None), ('limit', None), ('movie_rationales', None), ('evidence_infer_treatment', '2.0'), ('evidence_infer_treatment', '1.1'), ('lama', 'trex'), ('billsum', None), ('cbt', 'NE'), ('cbt', 'V'), ('cbt', 'P'), ('cbt', 'raw'), ('cbt', 'CN'), ('ncbi_disease', None), ('discofuse', 'discofuse-sport'), ('discofuse', 'discofuse-wikipedia'), ('ade_corpus_v2', 'Ade_corpus_v2_drug_ade_relation'), ('ade_corpus_v2', 'Ade_corpus_v2_classification'), ('ade_corpus_v2', 'Ade_corpus_v2_drug_dosage_relation'), ('qa_srl', None), ('gutenberg_time', None), ('subjqa', 'electronics'), ('subjqa', 'books'), ('subjqa', 'movies'), ('subjqa', 'tripadvisor'), ('subjqa', 'grocery'), ('subjqa', 'restaurants'), ('art', None), ('coqa', None), ('sms_spam', None), ('xsum', None), ('xnli', 'en'), ('banking77', None), ('amazon_reviews_multi', 'en'), ('openai_humaneval', None), ('anli', None), ('glue', 'wnli'), ('glue', 'sst2'), ('glue', 'mnli_mismatched'), ('glue', 'mnli'), ('glue', 'rte'), ('glue', 'cola'), ('glue', 'ax'), ('glue', 'qnli'), ('glue', 'mrpc'), ('glue', 'qqp'), ('glue', 'mnli_matched'), ('glue', 'stsb'), ('e2e_nlg_cleaned', None), ('app_reviews', None), ('conv_ai_3', None), ('tab_fact', 'tab_fact'), ('ropes', None), ('dream', None), ('dbpedia_14', None), ('cc_news', None), ('duorc', 'ParaphraseRC'), ('duorc', 'SelfRC'), ('covid_qa_castorini', None), ('ag_news', None), ('quora', None), ('aeslc', None), ('web_questions', None), ('amazon_polarity', None), ('guardian_authorship', 'cross_genre_1'), ('guardian_authorship', 'cross_topic_1'), ('guardian_authorship', 'cross_topic_7'), ('guardian_authorship', 'cross_topic_4'), ('gigaword', None), ('lambada', None), ('snips_built_in_intents', None), ('multi_x_science_sum', None), ('emo', None), ('poem_sentiment', None), ('selqa', 'answer_selection_analysis'), ('newspop', None), ('head_qa', 'en'), ('hans', None), ('onestop_english', None), ('medal', None), ('qa_zre', None), ('race', 'high'), ('race', 'all'), ('race', 'middle'), ('tweet_eval', 'offensive'), ('tweet_eval', 'stance_feminist'), ('tweet_eval', 'sentiment'), ('tweet_eval', 'emoji'), ('tweet_eval', 'emotion'), ('tweet_eval', 'irony'), ('tweet_eval', 'hate'), ('tweet_eval', 'stance_abortion'), ('tweet_eval', 'stance_climate'), ('tweet_eval', 'stance_atheism'), ('tweet_eval', 'stance_hillary'), ('humicroedit', 'subtask-2'), ('humicroedit', 'subtask-1'), ('zest', None), ('blbooksgenre', 'title_genre_classifiction'), ('quarel', None), ('health_fact', None), ('amazon_us_reviews', 'Wireless_v1_00'), ('squad', None), ('kilt_tasks', 'hotpotqa'), ('kilt_tasks', 'nq'), ('asset', 'simplification'), ('asset', 'ratings'), ('multi_news', None), ('quac', None), ('cord19', 'metadata'), ('trec', None), ('pubmed_qa', 'pqa_labeled'), ('wiqa', None)])\n"
     ]
    }
   ],
   "source": [
    "print(collection_templates.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    }
   ],
   "source": [
    "instructions = {}\n",
    "for k in list(collection_templates.keys()):\n",
    "    # print(k[0])\n",
    "    if k[0] in task_dataset_list:\n",
    "        dataset = collection_templates[k[0],k[1]].templates\n",
    "        for key in list(dataset.keys()):\n",
    "            instructions[str(k[0])+\"_\"+(str(k[1]) if k[1] is not None else \"\")+\"_\"+dataset[key].name.replace(\" \",\"_\").replace(\"-\",\"_\")] = dataset[key].jinja\n",
    "print(len(instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画TSNE图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n"
     ]
    }
   ],
   "source": [
    "print(model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
